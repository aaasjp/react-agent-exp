{"query": "deepagents examples", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://github.com/langchain-ai/deepagents", "title": "langchain-ai/deepagents: Deep Agents is an agent harness ... - GitHub", "content": "import os from deepagents import create_deep_agent from tavily import TavilyClient tavily_client = TavilyClient api_key = os environ \"TAVILY_API_KEY\" def internet_search query str max_results int = 5 \"\"\"Run a web search\"\"\" return tavily_client search query max_results = max_results agent = create_deep_agent tools = internet_search system_prompt =\"Conduct research and write a polished report.\" result = agent invoke \"messages\" \"role\" \"user\" \"content\" \"What is LangGraph?\". Deep agents use middleware for extensibility (see Built-in Tools for defaults). from deepagents import create_deep_agent research_subagent = \"name\"\"research-agent\" \"description\"\"Used to research in-depth questions\" \"system_prompt\" \"You are an expert researcher\" \"tools\" internet_search \"model\"\"openai:gpt-4o\"# Optional, defaults to main agent model agent = create_deep_agent subagents = research_subagent. from deepagents import CompiledSubAgent create_deep_agent custom_graph = create_agent model = tools = system_prompt = agent = create_deep_agent subagents = CompiledSubAgent name =\"data-analyzer\" description = \"Specialized agent for data analysis\" runnable = custom_graph. from langchain_core tools import tool from deepagents import create_deep_agent @tool tool def get_weather city str -> str\"\"\"Get the weather in a city.\"\"\" returnf\"The weather in {city} is sunny.\"{city}{city} agent = create_deep_agent model =\"anthropic:claude-sonnet-4-20250514\" tools = get_weather interrupt_on = \"get_weather\" \"allowed_decisions\" \"approve\" \"edit\" \"reject\".", "score": 0.74785584, "raw_content": "[Skip to content](#start-of-content)   \n\n\n\n## Navigation Menu\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Fdeepagents) \n\nAppearance settings\n\n# Search code, repositories, users, issues, pull requests...\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Fdeepagents)\n\n [Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=langchain-ai%2Fdeepagents) \n\nAppearance settings\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n{{ message }}\n\n[langchain-ai](/langchain-ai)   /  **[deepagents](/langchain-ai/deepagents)**  Public\n\n* [Notifications](/login?return_to=%2Flangchain-ai%2Fdeepagents)  You must be signed in to change notification settings\n* [Fork 1.2k](/login?return_to=%2Flangchain-ai%2Fdeepagents)\n* [Star  7.8k](/login?return_to=%2Flangchain-ai%2Fdeepagents)\n\nDeep Agents is an agent harness built on langchain and langgraph. Deep Agents are equipped with a planning tool, a filesystem backend, and the ability to spawn subagents - making them well-equipped to handle complex agentic tasks.\n\n[docs.langchain.com/oss/python/deepagents/overview](https://docs.langchain.com/oss/python/deepagents/overview \"https://docs.langchain.com/oss/python/deepagents/overview\")\n\n### License\n\n[MIT license](/langchain-ai/deepagents/blob/master/LICENSE)\n\n[7.8k stars](/langchain-ai/deepagents/stargazers)   [1.2k forks](/langchain-ai/deepagents/forks)   [Branches](/langchain-ai/deepagents/branches)   [Tags](/langchain-ai/deepagents/tags)   [Activity](/langchain-ai/deepagents/activity)\n\n[Star](/login?return_to=%2Flangchain-ai%2Fdeepagents)\n\n[Notifications](/login?return_to=%2Flangchain-ai%2Fdeepagents)  You must be signed in to change notification settings\n\n# langchain-ai/deepagents\n\n[Branches](/langchain-ai/deepagents/branches)[Tags](/langchain-ai/deepagents/tags)\n\nOpen more actions menu\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| Latest commit   History[225 Commits](/langchain-ai/deepagents/commits/master/) |\n| [.github](/langchain-ai/deepagents/tree/master/.github \".github\") | [.github](/langchain-ai/deepagents/tree/master/.github \".github\") |  |  |\n| [libs](/langchain-ai/deepagents/tree/master/libs \"libs\") | [libs](/langchain-ai/deepagents/tree/master/libs \"libs\") |  |  |\n| [.gitignore](/langchain-ai/deepagents/blob/master/.gitignore \".gitignore\") | [.gitignore](/langchain-ai/deepagents/blob/master/.gitignore \".gitignore\") |  |  |\n| [LICENSE](/langchain-ai/deepagents/blob/master/LICENSE \"LICENSE\") | [LICENSE](/langchain-ai/deepagents/blob/master/LICENSE \"LICENSE\") |  |  |\n| [README.md](/langchain-ai/deepagents/blob/master/README.md \"README.md\") | [README.md](/langchain-ai/deepagents/blob/master/README.md \"README.md\") |  |  |\n|  |\n\n## Repository files navigation\n\n# ðŸš€ðŸ§  Deep Agents\n\nAgents can increasingly tackle long-horizon tasks, [with agent task length doubling every 7 months](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/)! But, long horizon tasks often span dozens of tool calls, which present cost and reliability challenges. Popular agents such as [Claude Code](https://code.claude.com/docs) and [Manus](https://www.youtube.com/watch?v=6_BcCthVvb8) use some common principles to address these challenges, including **planning** (prior to task execution), **computer access** (giving the agent access to a shell and a filesystem), and **sub-agent delegation** (isolated task execution). `deepagents` is a simple agent harness that implements these tools, but is open source and easily extendable with your own custom tools and instructions.\n\n## ðŸ“š Resources\n\n* **[Documentation](https://docs.langchain.com/oss/python/deepagents/overview)** - Full overview and API reference\n* **[Quickstarts Repo](https://github.com/langchain-ai/deepagents-quickstarts)** - Examples and use-cases\n* **[CLI](/langchain-ai/deepagents/blob/master/libs/deepagents-cli)** - Interactive command-line interface with skills, memory, and HITL workflows\n\n## ðŸš€ Quickstart\n\nYou can give `deepagents` custom tools. Below, we'll optionally provide the `tavily` tool to search the web. This tool will be added to the `deepagents` build-in tools (see below).\n\n```\npip install deepagents tavily-python\n```\n\nSet `TAVILY_API_KEY` in your environment ([get one here](https://www.tavily.com/)):\n\n```\nimport os from deepagents import create_deep_agent from tavily import TavilyClient tavily_client = TavilyClient api_key = os environ \"TAVILY_API_KEY\" def internet_search query str max_results int = 5 \"\"\"Run a web search\"\"\" return tavily_client search query max_results = max_results agent = create_deep_agent tools = internet_search system_prompt =\"Conduct research and write a polished report.\" result = agent invoke \"messages\" \"role\" \"user\" \"content\" \"What is LangGraph?\"\n```\n\nThe agent created with `create_deep_agent` is compiled [LangGraph StateGraph](https://docs.langchain.com/oss/python/langgraph/overview), so it can be used with streaming, human-in-the-loop, memory, or Studio just like any LangGraph agent. See our [quickstarts repo](https://github.com/langchain-ai/deepagents-quickstarts) for more examples.\n\n## Customizing Deep Agents\n\nThere are several parameters you can pass to `create_deep_agent`.\n\n### `model`\n\nBy default, `deepagents` uses `\"claude-sonnet-4-5-20250929\"`. You can customize this by passing any [LangChain model object](https://python.langchain.com/docs/integrations/chat/).\n\n```\nfrom langchain chat_models import init_chat_model from deepagents import create_deep_agent model = init_chat_model\"openai:gpt-4o\" agent = create_deep_agent model = model\n```\n\n### `system_prompt`\n\nYou can provide a `system_prompt` parameter to `create_deep_agent()`. This custom prompt is **appended to** default instructions that are automatically injected by middleware.\n\nWhen writing a custom system prompt, you should:\n\n* âœ… Define domain-specific workflows (e.g., research methodology, data analysis steps)\n* âœ… Provide concrete examples for your use case\n* âœ… Add specialized guidance (e.g., \"batch similar research tasks into a single TODO\")\n* âœ… Define stopping criteria and resource limits\n* âœ… Explain how tools work together in your workflow\n\n**Don't:**\n\n* âŒ Re-explain what standard tools do (already covered by middleware)\n* âŒ Duplicate middleware instructions about tool usage\n* âŒ Contradict default instructions (work with them, not against them)\n\n```\nfrom deepagents import create_deep_agent research_instructions = \"\"\"your custom system prompt\"\"\" agent = create_deep_agent system_prompt = research_instructions\n```\n\nSee our [quickstarts repo](https://github.com/langchain-ai/deepagents-quickstarts) for more examples.\n\n### `tools`\n\nProvide custom tools to your agent (in addition to [Built-in Tools](#built-in-tools)):\n\n```\nfrom deepagents import create_deep_agent def internet_search query str -> str \"\"\"Run a web search\"\"\" return tavily_client search query agent = create_deep_agent tools = internet_search\n```\n\nYou can also connect MCP tools via [langchain-mcp-adapters](https://github.com/langchain-ai/langchain-mcp-adapters):\n\n```\nfrom langchain_mcp_adapters client import MultiServerMCPClient from deepagents import create_deep_agent async def main mcp_client = MultiServerMCPClient mcp_tools = await mcp_client get_tools agent = create_deep_agent tools = mcp_tools async for chunk in agent astream \"messages\" \"role\" \"user\" \"content\"\"...\" chunk \"messages\" - 1 pretty_print\n```\n\n### `middleware`\n\nDeep agents use [middleware](https://docs.langchain.com/oss/python/langchain/middleware) for extensibility (see [Built-in Tools](#built-in-tools) for defaults). Add custom middleware to inject tools, modify prompts, or hook into the agent lifecycle:\n\n```\nfrom langchain_core tools import tool from deepagents import create_deep_agent from langchain agents middleware import AgentMiddleware @tool tool def get_weather city str -> str\"\"\"Get the weather in a city.\"\"\" returnf\"The weather in {city} is sunny.\"{city}{city} class WeatherMiddleware AgentMiddleware tools = get_weather agent = create_deep_agent middleware = WeatherMiddleware\n```\n\n### `subagents`\n\nThe main agent can delegate work to sub-agents via the `task` tool (see [Built-in Tools](#built-in-tools)). You can supply custom sub-agents for context isolation and custom instructions:\n\n```\nfrom deepagents import create_deep_agent research_subagent = \"name\"\"research-agent\" \"description\"\"Used to research in-depth questions\" \"system_prompt\" \"You are an expert researcher\" \"tools\" internet_search \"model\"\"openai:gpt-4o\"# Optional, defaults to main agent model agent = create_deep_agent subagents = research_subagent\n```\n\nFor complex cases, pass a pre-built LangGraph graph:\n\n```\nfrom deepagents import CompiledSubAgent create_deep_agent custom_graph = create_agent model = tools = system_prompt = agent = create_deep_agent subagents = CompiledSubAgent name =\"data-analyzer\" description = \"Specialized agent for data analysis\" runnable = custom_graph\n```\n\nSee the [subagents documentation](https://docs.langchain.com/oss/python/deepagents/subagents) for more details.\n\n### `interrupt_on`\n\nSome tools may be sensitive and require human approval before execution. Deepagents supports human-in-the-loop workflows through LangGraphâ€™s interrupt capabilities. You can configure which tools require approval using a checkpointer.\n\nThese tool configs are passed to our prebuilt [HITL middleware](https://docs.langchain.com/oss/python/langchain/middleware#human-in-the-loop) so that the agent pauses execution and waits for feedback from the user before executing configured tools.\n\n```\nfrom langchain_core tools import tool from deepagents import create_deep_agent @tool tool def get_weather city str -> str\"\"\"Get the weather in a city.\"\"\" returnf\"The weather in {city} is sunny.\"{city}{city} agent = create_deep_agent model =\"anthropic:claude-sonnet-4-20250514\" tools = get_weather interrupt_on = \"get_weather\" \"allowed_decisions\" \"approve\" \"edit\" \"reject\"\n```\n\nSee the [human-in-the-loop documentation](https://docs.langchain.com/oss/python/deepagents/human-in-the-loop) for more details.\n\n### `backend`\n\nDeep agents use pluggable backends to control how filesystem operations work. By default, files are stored in the agent's ephemeral state. You can configure different backends for local disk access, persistent cross-conversation storage, or hybrid routing.\n\n```\nfrom deepagents import create_deep_agent from deepagents backends import FilesystemBackend agent = create_deep_agent backend = FilesystemBackend root_dir =\"/path/to/project\"\n```\n\nAvailable backends include:\n\n* **StateBackend** (default): Ephemeral files stored in agent state\n* **FilesystemBackend**: Real disk operations under a root directory\n* **StoreBackend**: Persistent storage using LangGraph Store\n* **CompositeBackend**: Route different paths to different backends\n\nSee the [backends documentation](https://docs.langchain.com/oss/python/deepagents/backends) for more details.\n\n### Long-term Memory\n\nDeep agents can maintain persistent memory across conversations using a `CompositeBackend` that routes specific paths to durable storage.\n\nThis enables hybrid memory where working files remain ephemeral while important data (like user preferences or knowledge bases) persists across threads.\n\n```\nfrom deepagents import create_deep_agent from deepagents backends import CompositeBackend StateBackend StoreBackend from langgraph store memory import InMemoryStore agent = create_deep_agent backend = CompositeBackend default = StateBackend routes =\"/memories/\" StoreBackend store = InMemoryStore\n```\n\nFiles under `/memories/` will persist across all conversations, while other paths remain temporary. Use cases include:\n\n* Preserving user preferences across sessions\n* Building knowledge bases from multiple conversations\n* Self-improving instructions based on feedback\n* Maintaining research progress across sessions\n\nSee the [long-term memory documentation](https://docs.langchain.com/oss/python/deepagents/long-term-memory) for more details.\n\n## Built-in Tools\n\nEvery deep agent created with `create_deep_agent` comes with a standard set of tools:\n\n| Tool Name | Description | Provided By |\n| --- | --- | --- |\n| `write_todos` | Create and manage structured task lists for tracking progress through complex workflows | TodoListMiddleware |\n| `read_todos` | Read the current todo list state | TodoListMiddleware |\n| `ls` | List all files in a directory (requires absolute path) | FilesystemMiddleware |\n| `read_file` | Read content from a file with optional pagination (offset/limit parameters) | FilesystemMiddleware |\n| `write_file` | Create a new file or completely overwrite an existing file | FilesystemMiddleware |\n| `edit_file` | Perform exact string replacements in files | FilesystemMiddleware |\n| `glob` | Find files matching a pattern (e.g., `**/*.py`) | FilesystemMiddleware |\n| `grep` | Search for text patterns within files | FilesystemMiddleware |\n| `execute`\\* | Run shell commands in a sandboxed environment | FilesystemMiddleware |\n| `task` | Delegate tasks to specialized sub-agents with isolated context windows | SubAgentMiddleware |\n\nThe `execute` tool is only available if the backend implements `SandboxBackendProtocol`. By default, it uses the in-memory state backend which does not support command execution. As shown, these tools (along with other capabilities) are provided by default middleware:\n\nSee the [agent harness documentation](https://docs.langchain.com/oss/python/deepagents/harness) for more details on built-in tools and capabilities.\n\n## Built-in Middleware\n\n`deepagents` uses middleware under the hood. Here is the list of the middleware used.\n\n| Middleware | Purpose |\n| --- | --- |\n| **TodoListMiddleware** | Task planning and progress tracking |\n| **FilesystemMiddleware** | File operations and context offloading (auto-saves large results) |\n| **SubAgentMiddleware** | Delegate tasks to isolated sub-agents |\n| **SummarizationMiddleware** | Auto-summarizes when context exceeds 170k tokens |\n| **AnthropicPromptCachingMiddleware** | Caches system prompts to reduce costs (Anthropic only) |\n| **PatchToolCallsMiddleware** | Fixes dangling tool calls from interruptions |\n| **HumanInTheLoopMiddleware** | Pauses execution for human approval (requires `interrupt_on` config) |\n\n## Built-in prompts\n\nThe middleware automatically adds instructions about the standard tools. Your custom instructions should **complement, not duplicate** these defaults:\n\n#### From [TodoListMiddleware](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/middleware/todo.py)\n\n* Explains when to use `write_todos` and `read_todos`\n* Guidance on marking tasks completed\n* Best practices for todo list management\n* When NOT to use todos (simple tasks)\n\n#### From [FilesystemMiddleware](/langchain-ai/deepagents/blob/master/libs/deepagents/deepagents/middleware/filesystem.py)\n\n* Lists all filesystem tools (`ls`, `read_file`, `write_file`, `edit_file`, `glob`, `grep`, `execute`\\*)\n* Explains that file paths must start with `/`\n* Describes each tool's purpose and parameters\n* Notes about context offloading for large tool results\n\n#### From [SubAgentMiddleware](/langchain-ai/deepagents/blob/master/libs/deepagents/deepagents/middleware/subagents.py)\n\n* Explains the `task()` tool for delegating to sub-agents\n* When to use sub-agents vs when NOT to use them\n* Guidance on parallel execution\n* Subagent lifecycle (spawn â†’ run â†’ return â†’ reconcile)\n\n## Security Considerations\n\n### Trust Model\n\nDeepagents follows a \"trust the LLM\" model similar to Claude Code. The agent can perform any action the underlying tools allow. Security boundaries should be enforced at the tool/sandbox level, not by expecting the LLM to self-police.\n\n## About\n\nDeep Agents is an agent harness built on langchain and langgraph. Deep Agents are equipped with a planning tool, a filesystem backend, and the ability to spawn subagents - making them well-equipped to handle complex agentic tasks.\n\n[docs.langchain.com/oss/python/deepagents/overview](https://docs.langchain.com/oss/python/deepagents/overview \"https://docs.langchain.com/oss/python/deepagents/overview\")\n\n### Topics\n\n[agents](/topics/agents \"Topic: agents\")   [langchain](/topics/langchain \"Topic: langchain\")   [langgraph](/topics/langgraph \"Topic: langgraph\")   [deepagents](/topics/deepagents \"Topic: deepagents\")\n\n### Resources\n\n### License\n\n[MIT license](#MIT-1-ov-file)\n\n### Code of conduct\n\n[Code of conduct](#coc-ov-file)\n\n### Contributing\n\n### Security policy\n\n[Security policy](#security-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Custom properties](/langchain-ai/deepagents/custom-properties)\n\n### Stars\n\n[**7.8k** stars](/langchain-ai/deepagents/stargazers)\n\n### Watchers\n\n[**65** watching](/langchain-ai/deepagents/watchers)\n\n### Forks\n\n[**1.2k** forks](/langchain-ai/deepagents/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Fdeepagents&report=langchain-ai+%28user%29)\n\n## [Releases 11](/langchain-ai/deepagents/releases)\n\n[deepagents==0.3.1  Latest\n\nDec 23, 2025](/langchain-ai/deepagents/releases/tag/deepagents%3D%3D0.3.1)\n\n[+ 10 releases](/langchain-ai/deepagents/releases)\n\n## [Packages 0](/orgs/langchain-ai/packages?repo_name=deepagents)\n\nNo packages published\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n## [Contributors 37](/langchain-ai/deepagents/graphs/contributors)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[+ 23 contributors](/langchain-ai/deepagents/graphs/contributors)\n\n## Languages\n\n* [Python 99.3%](/langchain-ai/deepagents/search?l=python)\n* [Makefile 0.7%](/langchain-ai/deepagents/search?l=makefile)\n\nYou canâ€™t perform that action at this time.\n\n "}, {"url": "https://medium.com/@dtunai/streaming-deepagents-and-task-delegation-with-real-time-output-023e9ec049ba", "title": "Streaming deepagents and task delegation with real-time output", "content": "This post demonstrates how to implement streaming capabilities on top of DeepAgentsâ€™ package with multi-agent setup, with practical code examples and architectural patterns you can apply to your own projects. # Traditional approach - blockingagent = create_deep_agent(...)result = agent.run(task) # Wait for complete responseprint(result)# Streaming approach - async generatoragent = StreamingDeepAgent(role=AgentRole.COORDINATOR)async for token in agent.stream_response(task): print(token, end=\"\", flush=True) # Display each token immediately. On purpose, our implementation combines agent specialization, task delegation and real-time streaming. âœ“ Added agent: Coordinator (coordinator)âœ“ Added agent: Researcher (researcher)âœ“ Added agent: Coder (coder)âœ“ Added agent: Reviewer (reviewer)âœ“ Added agent: Documenter (documenter)Processing Complex Task: Build a user authentication systemCoordinator analyzing task...[Streams task breakdown in real-time]â†’ Delegating to Researcher: Research best practices...â†’ Delegating to Coder: Implement authentication logic...â†’ Delegating to Documenter: Create API documentation...â†’ Delegating to Reviewer: Review security implementation... The key difference from traditional CLIs is that you see everything happening in real-time, the Coordinatorâ€™s analysis streams token by token, then multiple agents work in parallel, each streaming their outputs as they generate them.", "score": 0.7352811, "raw_content": "[Sitemap](/sitemap/sitemap.xml)\n\n[Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&referrer=utm_source%3DmobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\n\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40dtunai%2Fstreaming-deepagents-and-task-delegation-with-real-time-output-023e9ec049ba&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40dtunai%2Fstreaming-deepagents-and-task-delegation-with-real-time-output-023e9ec049ba&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n# **Streaming deepagents and task delegation with real-time output**\n\n[Dogukan Tuna](/@dtunai?source=post_page---byline--023e9ec049ba---------------------------------------)\n\n8 min read\n\nÂ·\n\nOct 21, 2025\n\n--\n\n> Using an LLM to call tools in a loop is the simplest form of an agent. This architecture, however, can yield agents that are â€œshallowâ€ and fail to plan and act over longer, more complex tasks.\n>\n> Applications like â€œDeep Researchâ€, â€œManusâ€, and â€œClaude Codeâ€ have gotten around this limitation by implementing a combination of four things: a planning tool, sub agents, access to a file system, and a detailed prompt.\n\n`deepagents` is a Python package that implements these in a general purpose way so that you can easily create a Deep Agent for your application. Heavily inspired by **Claude Code.**\n\nDeepAgents provides a powerful framework for building AI agents that can plan, delegate to sub-agents and maintain context across complex tasks. One enhancement that can significantly improve user experience is real-time streaming, seeing responses form token by token rather than waiting for complete outputs.\n\nThis post demonstrates how to implement streaming capabilities on top of DeepAgentsâ€™ package with multi-agent setup, with practical code examples and architectural patterns you can apply to your own projects.\n\n[## GitHub - dtunai/Streaming-DeepAgents: Example streaming and task delegation for Langchain'sâ€¦\n\n### Example streaming and task delegation for Langchain's Deepagents - dtunai/Streaming-DeepAgents\n\ngithub.com](https://github.com/dtunai/streaming-deepagents?source=post_page-----023e9ec049ba---------------------------------------)\n\n> ***Full Implementation****: The complete source code for this implementation is available at* [*github.com/dtunai/streaming-deepagents*](https://github.com/dtunai/streaming-deepagents)*. See particularly* `streaming_deep_agents.py` *for the core streaming architecture.*\n\n## What Are Deep Agents?\n\ndeepagents move beyond simple LLM wrappers or sequential / static agent architectures to create sophisticated multi-agent systems by acting in a ReACT **â€œreasoning and actingâ€** framework. So, the architecture enables:\n\n* **Task Planning**\n\nBreaking down complex requests into manageable subtasks\n\n* **Hierarchical Delegation**\n\nAssigning work to specialized sub-agents\n\n* **Context Management**\n\nMaintaining state across operations via middleware\n\n* **Parallel Execution**\n\nRunning multiple agents simultaneously\n\nAnd our implementation guide focuses on this blog post adding **real-time streaming** and parallelization to deepagents.\n\n## Implementing the Streaming Layer\n\nThe key difference between traditional and streaming agents lies in how responses are handled:\n\n```\n# Traditional approach - blockingagent = create_deep_agent(...)result = agent.run(task) # Wait for complete responseprint(result)# Streaming approach - async generatoragent = StreamingDeepAgent(role=AgentRole.COORDINATOR)async for token in agent.stream_response(task): print(token, end=\"\", flush=True) # Display each token immediately\n```\n\nThis pattern provides immediate feedback and allows users to see the agentâ€™s reasoning unfold in real-time.\n\n## **Architecture Overview**\n\nOn purpose, our implementation combines agent specialization, task delegation and real-time streaming. When processing a complex task, the flow looks like this:\n\n```\nUser: \"Build a REST API with authentication and rate limiting\" â†“[Coordinator Agent] â†’ Breaks down into subtasks â†“ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â†“ â†“ â†“ â†“Researcher Coder Documenter Reviewer(Best (FastAPI (API (Securitypractices) impl.) docs) check)\n```\n\nEach agent has a specific role and optimized parameters:\n\n```\nclass StreamingDeepAgent: def __init__(self, role: AgentRole, temperature: float): # Coder uses low temperature (0.3) for consistency # Researcher uses higher (0.7) for exploration # Each agent optimized for its specific task\n```\n\n## A Real Example: Building a REST API\n\nThe core insight is that complex tasks naturally decompose into specialized subtasks. Instead of forcing a single model to handle everything, we can create a system where:\n\n* A **Coordinator** agent breaks down complex requests into subtasks\n* Specialized agents (**Researcher**, **Coder**, **Reviewer**, **Documenter**) handle their own domains or their own targets\n* Responses stream in real-time as tokens are generated\n* Tasks execute in parallel when dependencies allow\n\nThis isnâ€™t just about dividing work, or just making optimization, itâ€™s about matching structural agentic patterns to problem structures.\n\n## Streaming\n\nReal-time streaming fundamentally one of the most important things that changes the user experience when interacting with agent systems and LLMs. Instead of staring at a loading spinner for 30 seconds, users wants to see thoughts forming, code being written and ideas or proposition.\n\n## Token-Level Streaming\n\nAt the lowest level, we intercept tokens as theyâ€™re generated by the language model:\n\n```\nasync def stream_response(self, prompt: str) -> AsyncIterator[str]: # Create callback to capture tokens self.stream_callback = StreamingCallback() self.llm.callbacks = [self.stream_callback] # Start generation asynchronously generation_task = asyncio.create_task( self.llm.ainvoke([HumanMessage(content=prompt)]) )\n```\n\n```\n # Stream tokens as they arrive async for token in self.stream_callback.get_stream(): yield token  await generation_task\n```\n\nThe key here is the async generator pattern â€” we yield tokens immediately as they become available, rather than waiting for completion.\n\n## Async Queue for Decoupling Token Generation\n\nStreaming callback uses an async queue to decouple token generation from consumption:\n\n```\nclass StreamingCallback(AsyncCallbackHandler): def __init__(self): self.streaming_queue = asyncio.Queue() async def on_llm_new_token(self, token: str, **kwargs): await self.streaming_queue.put(token) async def get_stream(self) -> AsyncIterator[str]: while True: token = await self.streaming_queue.get() if token is None: # End signal break yield token\n```\n\n## Task Delegation and Parallel Execution\n\nThe orchestratorâ€™s role is crucial. When a complex task arrives, it doesnâ€™t just split it randomly , it understands the semantic structure:\n\n```\nasync def process_complex_task(self, main_task: str): # Coordinator analyzes and breaks down the task breakdown = await coordinator.stream_response( f\"Break down this task into subtasks: {main_task}\" ) # Create subtasks based on analysis subtasks = self._create_subtasks(main_task) # Execute in parallel where possible results = await asyncio.gather( self.delegate_task(subtasks[0], \"Researcher\"), self.delegate_task(subtasks[1], \"Coder\"), self.delegate_task(subtasks[2], \"Documenter\") )\n```\n\nDeep Agents when they are instructed understands dependencies, research might need to complete before problem solving begins, but documentation can start in parallel with implementation.\n\n## Agent Specialization Through Prompting\n\nEach agent also needs a carefully crafted system prompt that shapes its behavior:\n\n* **Coordinator**\n\nFocuses on decomposition and delegation\n\n* **Researcher**\n\nPrioritizes accuracy and comprehensiveness\n\n* **Coder**\n\nEmphasizes clean, production-ready implementations\n\n* **Reviewer**\n\nLooks for bugs, security issues, and optimizations\n\n* **Documenter**\n\nCreates clear, user-friendly documentation\n\nSpecialization it can also be extended to the model parameters or better context engineering. But for the parameters, code generation uses lower temperature e.g. consistency, while research uses higher temperature for creative exploration by purpose.\n\n## Practical Implications\n\nDeepagents has several non-obvious benefits:\n\n### 1. Cognitive Load Distribution\n\nJust as humans work better in specialized teams, AI agents perform better when focused on specific domains. A coding agent doesnâ€™t need to worry about documentation style and a reviewer doesnâ€™t need to generate implementations.\n\n### 2. Parallel Processing\n\nWhen tasks are independent, they execute simultaneously. This isnâ€™t just about speed, itâ€™s about utilizing completions efficiently. While one agent researches best practices, another can already start drafting implementation templates.\n\n### 3. Feedback Loops\n\nThe reviewer agent provides a natural feedback mechanism. Its analysis can trigger refinements in other agentsâ€™ outputs, creating an iterative improvement cycle.\n\n### 4. Transparency\n\nStreaming responses with clear agent attribution makes the systemâ€™s reasoning transparent. Users can see which agent is contributing what, understanding the thought process behind complex outputs.\n\n## Implementation Considerations\n\nBuilding system with deepagents requires careful attention to several aspects:\n\n**State Management**: Tasks need persistent state to track progress, dependencies, and results. For example in our implementation we use a simple but effective Task *dataclass* with status tracking and timestamps.\n\n**Error Handling**: Distributed systems fail in distributed ways. Each agent needs graceful degradation or circuit breaking, if the Reviewer fails, the system should still provide the core implementation.\n\n**Rate Limiting**: With multiple agents potentially making parallel API calls, rate limiting becomes critical. The system implements configurable parallel execution limits.\n\n**Token Economics**: Multiple agents mean multiple API calls. The system needs to balance thoroughness with token consumption, using techniques like response summarization and selective delegation.\n\n## Interactive CLI Implementation\n\nTo make these concepts accessible, Iâ€™ve built a very simple command-line interface that demonstrates streaming deep agents in action. The CLI provides both interactive and direct command modes for experimenting with the architecture.\n\n### Basic Usage\n\n```\n# Start interactive modepython cli.py# Chat directly with a specific agentpython cli.py chat -a \"Coder\" -p \"Write a binary search function\"# Process a complex task with automatic delegationpython cli.py task -p \"Create a REST API with authentication\"\n```\n\n### Task Delegation in Action\n\nWhen you give the CLI a complex task, you can watch the entire orchestration process:\n\n```\n$ python cli.py task -p \"Build a user authentication system\"\n```\n\n```\nâœ“ Added agent: Coordinator (coordinator)âœ“ Added agent: Researcher (researcher)âœ“ Added agent: Coder (coder)âœ“ Added agent: Reviewer (reviewer)âœ“ Added agent: Documenter (documenter)Processing Complex Task: Build a user authentication systemCoordinator analyzing task...[Streams task breakdown in real-time]â†’ Delegating to Researcher: Research best practices...â†’ Delegating to Coder: Implement authentication logic...â†’ Delegating to Documenter: Create API documentation...â†’ Delegating to Reviewer: Review security implementation...\n```\n\nThe key difference from traditional CLIs is that you see everything happening in real-time, the Coordinatorâ€™s analysis streams token by token, then multiple agents work in parallel, each streaming their outputs as they generate them.\n\n### Creating Custom Agents\n\nCLI also allows you to create agents with specific parameters:\n\n```\n# In the CLI's interactive modeCommand: addAgent name: DataAnalystAgent role: researcherModel name: gpt-4.1Temperature (0.0-1.0): 0.5Enable streaming? [y/n]: y\n```\n\nThis flexibility lets you experiment with different agent configurations and see how temperature, role and model selection affect the streaming outputs.\n\n## Conclusion\n\nBuilding streaming deep agent systems is about recognizing that complex problems have inherent structure. By matching our architecture to this structure, through specialization, parallelization and real-time feedback, we can create systems that are not just more capable, but more understandable and controllable.\n\nKey takeaways from this implementation:\n\n1. **Async generators** enable token-by-token streaming without blocking\n\n2. **Queue-based architecture** decouples generation from consumption\n\n3. **Role specialization** improves output quality by focusing agents on specific domains\n\n4. **Parallel execution** reduces overall response time for complex tasks\n\nThe shift from monolithic to orchestrated agent systems parallels the evolution weâ€™ve seen in software architecture. Just as microservices revolutionized how we build scalable applications, agent orchestration is reshaping how we build AI systems.\n\n[## Streaming deepagents and task delegation with real-time output\n\n### This post demonstrates how to implement streaming capabilities on top of DeepAgents' package with multi-agent setupâ€¦\n\ndtai.blog](https://dtai.blog/blog/streaming-deep-agents-and-task-delegation?source=post_page-----023e9ec049ba---------------------------------------)\n\n*Want to experiment with streaming deep agents through simple CLI? Check out open-source implementation:* [*github.com/dtunai/streaming-deepagents*](https://github.com/dtunai/streaming-deepagents)\n\n*The repository includes a complete implementation with LangChain integration, real-time streaming, parallel task execution and a CLI for interactive experimentation. The architecture described in this post is fully implemented and ready to extend for your own use cases.*\n\n[Large Language Models](/tag/large-language-models?source=post_page-----023e9ec049ba---------------------------------------)\n\n[AI Agent](/tag/ai-agent?source=post_page-----023e9ec049ba---------------------------------------)\n\n[Langchain](/tag/langchain?source=post_page-----023e9ec049ba---------------------------------------)\n\n[Langchain Agents](/tag/langchain-agents?source=post_page-----023e9ec049ba---------------------------------------)\n\n[Software Development](/tag/software-development?source=post_page-----023e9ec049ba---------------------------------------)\n\n[## Written by Dogukan Tuna](/@dtunai?source=post_page---post_author_info--023e9ec049ba---------------------------------------)\n\n[121 followers](/@dtunai/followers?source=post_page---post_author_info--023e9ec049ba---------------------------------------)\n\nÂ·[15 following](/@dtunai/following?source=post_page---post_author_info--023e9ec049ba---------------------------------------)\n\nWebsite: [dtunai.blog](http://dtunai.blog)\n\n## No responses yet\n\n[Text to speech](https://speechify.com/medium?source=post_page-----023e9ec049ba---------------------------------------)"}, {"url": "https://www.youtube.com/watch?v=5tn6O0uXYEg", "title": "Build a Research Agent with Deep Agents - YouTube", "content": "Build a Research Agent with Deep Agents\nLangChain\n164000 subscribers\n463 likes\n15932 views\n20 Nov 2025\nDeepagents is a simple, open source agent harness built by LangChain. It uses some common principle seen in popular agents such as Claude Code and Manus, including planning (prior to task execution), computer access (giving the able access to a shell and a filesystem), and sub-agent delegation (isolated task execution). We're introducing a new repo with a collection of quickstarts that demonstrate different agents can be easily configured on top of the deepagents harness.\n\nQuickstarts repo:\nhttps://github.com/langchain-ai/deepagents-quickstarts\n\nLearn how to build Deep Agents on LangChain Academy:\nhttps://academy.langchain.com/courses/deep-agents-with-langgraph/?utm_medium=social&utm_source=youtube&utm_campaign=q4-2025_youtube-academy-links_aw\n\ndeepagents repo:\nhttps://github.com/langchain-ai/deepagents\n\ndeepagents docs:\nhttps://bit.ly/480icl1\n\ndeepagents UI:\nhttps://github.com/langchain-ai/deep-agents-ui\n\nChapters -- \n0:00 Introduction to DeepAgents\n1:00 Agent Trajectory Overview\n2:00 Built-in Tools in DeepAgents\n3:00 Quick Start Setup Options\n4:00 Task-Specific Tools: Search & Think\n5:00 Task-Specific Instructions\n6:00 Preventing Agent Spin Out\n7:00 Custom Prompts & Instructions\n8:00 Custom Subagents for Context Isolation\n9:00 Workflow Instructions & Delegation Strategy\n10:00 Initializing DeepAgent\n11:00 Middleware Overview\n12:00 Running the Agent in Notebook\n13:00 File System Backends\n14:00 Subagent Research Output\n15:00 LangSmith Tracing\n16:00 Deploying with LangGraph Server\n17:00 Summary & Key Takeaways\n15 comments\n", "score": 0.680136, "raw_content": "# Build a Research Agent with Deep Agents\n## LangChain\n164000 subscribers\n463 likes\n\n### Description\n15932 views\nPosted: 20 Nov 2025\nDeepagents is a simple, open source agent harness built by LangChain. It uses some common principle seen in popular agents such as Claude Code and Manus, including planning (prior to task execution), computer access (giving the able access to a shell and a filesystem), and sub-agent delegation (isolated task execution). We're introducing a new repo with a collection of quickstarts that demonstrate different agents can be easily configured on top of the deepagents harness.\n\nQuickstarts repo:\nhttps://github.com/langchain-ai/deepagents-quickstarts\n\nLearn how to build Deep Agents on LangChain Academy:\nhttps://academy.langchain.com/courses/deep-agents-with-langgraph/?utm_medium=social&utm_source=youtube&utm_campaign=q4-2025_youtube-academy-links_aw\n\ndeepagents repo:\nhttps://github.com/langchain-ai/deepagents\n\ndeepagents docs:\nhttps://bit.ly/480icl1\n\ndeepagents UI:\nhttps://github.com/langchain-ai/deep-agents-ui\n\nChapters -- \n0:00 Introduction to DeepAgents\n1:00 Agent Trajectory Overview\n2:00 Built-in Tools in DeepAgents\n3:00 Quick Start Setup Options\n4:00 Task-Specific Tools: Search & Think\n5:00 Task-Specific Instructions\n6:00 Preventing Agent Spin Out\n7:00 Custom Prompts & Instructions\n8:00 Custom Subagents for Context Isolation\n9:00 Workflow Instructions & Delegation Strategy\n10:00 Initializing DeepAgent\n11:00 Middleware Overview\n12:00 Running the Agent in Notebook\n13:00 File System Backends\n14:00 Subagent Research Output\n15:00 LangSmith Tracing\n16:00 Deploying with LangGraph Server\n17:00 Summary & Key Takeaways\n\n15 comments\n### Transcript:\nHey, this is Lance from Langchain. So, deep agents is a simple open- source agent harness that implements a few ideas we've seen across many popular agents like Manis, like cloud code, notably planning, computer access, and subent delegation. So, this open source harness bakes in these tools for you, but is easily extendable. You can provide custom prompts, you can provide custom tools, and it's all open source. You can modify it any way you want. Now to help people get started with different applications of deep agents, we created this deep agent quick start repo which has a number of folders for different use cases starting with research because we've done so much on research already. It's such a popular use case that I want to showcase it. So first I'm going to show this running and then I'm going to walk through everything that's happening under the hood. So here's a deep a so here's a UI that we built custom for deep agents. I have this running locally. Submit my research request. run. And so we can see research finishing up here. And so our deep agent research task finished. Now what you see here are all the different tool calls that are made throughout the trajectory. You can open each of these up. You can look at the arguments of the tool call. You can see it follows this trajectory of tool calls. It gives us a summary of what it's done. We can open up any files it generated. And here is the final report that it generated for us. Nicely cited. And when you look at this trajectory, you see a bunch of different tool calls. Write file, write to-dos, tavly search, think tool, read file, write to-dos. What are these? Where are they coming from? What's kind of going on under the hood here. So, let's talk about that a little bit. In the repo, you can see here there's a list of folders. In this case, only one. We only have a single quick start for research. And this is built on top of the deep agents package. And you can see that repo here, lane chain deep agents. And if you scroll down in the readme, there's something that's very simple and important to understand. With every deep agent, you have a few built-in tools that you can use. A planning tool, sub aent delegation tool, various file system tools, as well as any tools you provide or instructions you provide. So this table lists all the different built-in tools that you get with DB agents out of the box. And we can see that these tool names are identical to what we saw in that agent trajectory. write to-dos, read to-dos, list files, read file, write file, edit file, glob grip, execute shell commands, and a task tool to de delegate out work to sub aents. Now, this simple set of atomic tools allow you to do a very large number of things because it lets you interact with a file system, call shell commands, plan through to-dos, delegate tasks through this task tool. And you'll recognize that these tools are quite similar to what you see when you're using Manis or using cloud code that similarly have access to a file system. In the case of cloud code, typically it's your local file system. In the case of Manis, it's a sandbox, have sub aent delegation tools, and have the ability to plan. These are the fundamental things that we see that are very important for building longunning agents capable of handling complex tasks. So now that you understand the fundamental tools that are baked into deep agents package, quick starts is pretty easy to follow. If we open up the deep research quickart directory and so I'm in the readme for the deep agents quickart and what's nice is you can interact with this quick start a few different ways. You can just simply run a Jupyter notebook which I'll show you right now or you can run langraph server locally and connect it to a UI like for example the UI we were looking at previously. I'll show that a bit later. So, first let's just kick this off. You can run this command in your terminal from this directory. Spin up a notebook. So, here it is. Notebook's running. And the way think about any of these quick starts is four different things. First, understand the native tools available to you when using deep agents. We just talked through that. That's a table of tools I showed in the readme. And then for any given use case, you want to supply a few different things. any task specific tools, task specific instructions or task specific sub aents. Now for research, I'm going to supply two different specific tools. One is a search tool, the other is a think tool. The search tools can be used to search for relevant URLs to my query and then fetch the full web page contents. Pretty intuitive. A think tool is completely optional. I tend to like it for auditing. It's just a tool that the agent can call that enforces interle thinking. Now note that some SDKs like claude have this built in but it's not always the case. So this think tool is a nice way to explicitly tell the agent to think between steps and you can instruct it accordingly when to call the think tool. So it's very useful for auditing the agent trajectory and what it's doing at different points in time. But of course completely optional. You don't have to use it. I just tend to like to. And if you look at the readme in that deep research folder, look at the research agent folder. The tools are defined right there in this tools.py. This is a very simple search tool defined here using Tavali search API. But you can use any search API you want and again a think tool which doesn't actually do anything. And this is important to note. It just forces the agent to pause and produce a reflection. So I import those tools. We have them available. Now, this is the part that often is the most important and can be quite tricky. Taskm instructions. Of course, prompting is not dead. It's still very much alive and very important with agents. Here, I added a few tips that I tend to like and I've used in the past for prompting agents for tastic research. I got this from a video that was really nice from some folks at Anthropic. Think like the agent. In this particular case, what instructions would you give a new colleague related to research task? Read the question carefully. Start with broad searches. Pause and pause and assess. Use narrower searches to gather information. So just some heristics about how to perform research. Now this one I found to be very important from some prior work and research. Heristic to prevent spin out. So stop when you can answer correctly. Give budgets for the number of tool calls that you wanted to per perform at maximum. Give it limits. Always stop after some number of tool calls. I've seen cases where the agent will continue doing searches to refine its result without stopping. And so these heristics can be very helpful for preventing spin out as you might call it, which just means continuing to make tool calls to search for further and further information long after you've collected enough information to actually answer the question. And I ask NIS agent to show its thinking. And again, I use that think tool to enforce it. And again [clears throat] looking at the repo, the prompts I all check in here in this prompts.py. And again, you can modify these any way you want. Of course, this is just a starting point that I found to be pretty useful. I import the prompts here. We can look at them. So they follow the heristics I talked about above. These are instructions for the researcher. For example, I tell it the available tools. I give it instructions, you know, think like a researcher with limited time. I give it budgets. I ask it to show its thinking. and I provide some final response formatting in my instructions. Now, one other thing that's nice about deep agents is you can supply custom sub agents. So, remember deep agents has that task tool that can use to delegate tasks to sub agents. Now, why do we do this? This is actually very useful for context isolation. The main idea is simply that a research task can be really tokenheavy and if you want to research a particular question, you can delegate that out to sub agent. it can go off and do a bunch of searches, learn a bunch of information, pass that result back to your main agent as a result. So, it's a really nice way to compartmentalize or isolate all the context collected in that research task in the isolate context window of the sub agent and just return the result. So, that's why these sub aents are really nice particularly for research. In this case, I can just initialize one. It's just a dictionary. Deep agents accepts this. Give it a name, give it a description, and I give it some instructions. So, whenever this stub agent spawns, it receives the researcher instructions, and I give it the tools. I can put this all together into some general workflow instructions. So, this is what the overall deep agent will receive in terms of how to conduct research, sub aent delegation instructions, when to delegate to sub agents, and the researcher instructions, again, how to perform research. And I can show this consolidated prompt. And in these workflow instructions, I'm actually going to tell the agent to use its native tools occasionally. Remember, that's why it's very important to actually understand the native tools built into deep agents for you. In this case, I want to remember the user's research request. So, I'm going to have the deep agent call its write file tool to save the research request to this file research request. MD. I'm going to tell it to use its to-do list tool to write to-dos to break down the research task. I'm going to tell it to use its task tool to delegate research and I'm going to have it write a fun report. And I'll reinforce some report lighting guidelines here. And I provide some rules here for sub aent delegation because I found that elements can be a little bit too eager with sub aent delegation and spawn like five different sub aents for things that really can be grouped into a single sub aent call. So I do think it's important to lay out a crisp delegation strategy for your use case. And then finally the research instructions themselves. Now once you have those things defined actually initializing the deep agent is trivial. From deep agents you import create deep agent you pass the model you want to use. You pass the tools you pass the instructions and you pass any custom sub agents. And now the nice thing here is deep agents is abstracting only a few things. in particular to distracting a set of built-in default atomic and very general tools that we found to be useful across many applications notably what I just showed task tool for subage delegation to-do list file system operations those things are very general you want them across many different age applications you don't want to reimplement them every time for each agent you're building so it's baked into the harness for you but it's very important to think through your prompting your sub aents and of course whatever custom tools you So we add them all here. We show this. Now this middleware thing is kind of odd, right? Like what is all this? So middleware is just what we use in Langraph to help orchestrate the agent loop. Remember an agent loop is very simply an LM calling tools in a loop. But you often want stop at particular points in this loop and do different things. Middleware can serve as hooks. stopping for example before the agent before the model before tools are called. So at different points in this agent loop you can inject middleware to stop and do something. Now not only that middleware can also provide tools and so in particular in the readme for deep agents I've added a table that shows you for every tool what middleware provides it. So you can kind of think about file system middleware as providing a tool set to the agent and this is a list of all the middleware that's used under the hood with deep agents. So again it has to-do list middleware that provides the task related tools right here file system middleware sub aent middleware for delegation those are all pretty obvious those are kind of acting as tool sets but also middleware can act more as like hooks. So we have this summarization middleware. This auto summarizes whenever the context exceeds 170,000 tokens and this is configured for enthropic models. You can tune this for other models if you need and this is acting in the same way that compaction works in for example cloud code. Prompt caching middleware is built in which is available with anthropic only. We have this patch tool calls middleware which fixes dangling tool calls. And we have human loop middleware which can pause execution for human approval at different steps. And so the way to think about this is this middleware is acting at different points in this agent life cycle doing different things. Not only can it basically serve tools to the agent like we see with for example file system middleware but it can also do things like summarization as you can see before the model. We summarize the message history if it exceeds a token limit. And you can read more about middleware in our documentation which I'll link in the video description. Now we can run this in our notebook and now you understand where the different tools are coming from and the instructions we've given their agent. So you can see that when I kick off this process because the instructions I've given it, it's going to write the user's request to a file using its write file tool. It's also going to write to it's going to use its write to-dos tool to create a bunch of research to-dos. Now I want to call something out important here. When you see this write file tool call and you see this file path, what's going on here? Is this writing to your file system or what? So actually by default deep agent it will only write to an internal inmemory state object. What's really nice is deep agent is built on langraph. Langraph has this notion of a state object and so it can write these files to state and then read them back from state. Now that will persist in memory during the course of the agent execution. But deep agent does support different backends. If you want to access a file system, you can easily do that. So by default, it'll just use its in-memory state object for file reading and writing and manipulation. But it can also use different backends like a sandbox or like a local file system. So again, I'll share that in the video description and provide documentation on different backends if you want to try that. We can see after it writes its to-dos, after it writes its file, it'll call its task tool. This will kick off a research agent and it's initialized with description of a research task which is great. And we can see we now get the outputs of all those tool calls. We updated a file. We updated to-dos and this is the output of the sub aent. So you can see the sub aent returns its entire research output back to the parent which is great. We can see it's very extensive deep dive, very nice, well sourced, everything we would want. We update our to-dos. We then write a file final report.md based upon all the result all the research done by the sub agent which is great update the todo list to note that we have completed our task the file is written we do a verification to confirm the report addresses the original question which we have saved you can see right here we can read that research request file to confirm that a report actually addresses it and then what's nice is all these file reading and write operations are all happening within the langraph state object all in memory, but you can pull it back into the context window of the LM very easily from the state object. So you can really think about this as a way of performing recitation. Write the request to state, do a bunch of stuff, then read it back in to make sure you've actually addressed the request. This is a very nice trick that actually Manis talks about quite a bit to steer agents and ensure they stay on track. And the final verification is done. The agent returns quick summary of what it's learned and the final report is of course saved to the langraph state object. Because we're using Langraph under the hood, of course, this is all traced to Langsmith. You can open up Langsmith and open up the trace and you can look at all those individual tool calls if you want as well as all the different model calls. You can see we're using clonet cla and this is the entire researchation trajectory that we all have saved and logged for us in Langmith. And that shows you how to run this entire process in a notebook which is quite nice for interactive inspection of prompts. Now if you want to run this as a deployable application, you can just very simply run langraph dev just like this. That spins up a langraph server. Now the server has this built-in interface called studio which you can use to run the agent. And the readme also has instructions for connecting it to connecting this local deployment up with deep agent UI. That's all right here which we worked with right here. So again the what's happening here is I have the deep agent quick starts repo. I have the directory which has the deep research example. I ran langraph dev in that directory that spun up a local langraph server. And then I just connected it with this UI. That's it. And then I can interact with graph server which encapsulates my agent using this UI which allows me to very nicely visualize the files that it generated. So if you pull all the way back out, what's going on here? Deep agents is an open source agent harness that features a number of commonly used tools for planning, for computer access, for sub aent delegation. We see these tools used across many agent applications. Manis uses them, cloud code uses them. So they're very common atomic powerful tools. Deep agents implements them for you and you can easily adapt it for your use case with custom tools, custom instructions, custom sub agents. Deep agent quick start then built built upon the deep agents package and has some nice out of the box agent and has some nice out of- the box examples starting with research because it's such a popular one. We've done so much on it. Again, you can check that research readme that shows you how to for example run it very quickly in a notebook as well as a local graph server which connect to a UI. All the code necessary is right in here. You for example just prompts and tools we provide for the research task and the agent itself is initialized in this script as well as in a notebook which we saw right here. The key point to keep in mind is deep agents is very general. It's easily adaptable for a given use case. Prompting and tool definition are really the things you need to think about quite a bit. And it's very important to understand the base capabilities and tools built into the harness so you can adapt it. And that's what we really tried to explain in the quick start readme by laying out down here all the built-in components within deep agents that you need to understand in order in order to best make use of it. So hopefully this was a useful overview. We're going to be adding to this repo. If you have specific examples you want added, feel free to just comment in the video. We can get to them. And it's all open source as well. Also feel free to just contribute directly. Thanks a lot."}, {"url": "https://www.datacamp.com/tutorial/deep-agents", "title": "LangChain's Deep Agents: A Guide With Demo Project - DataCamp", "content": "Keep writing tight and specific.\" ) def build_agent(): api_key = os.environ.get(\"OPENAI_API_KEY\") if not api_key: st.error(\"Please set OPENAI_API_KEY in your environment.\") st.stop() llm = ChatOpenAI(model=os.environ.get(\"OPENAI_MODEL\", \"gpt-4o-mini\"), temperature=0.2) tools = [internet_search] subagents = [ {\"name\": \"job-search-agent\", \"description\": \"Finds relevant jobs\", \"prompt\": JOB_SEARCH_PROMPT}, {\"name\": \"cover-letter-writer-agent\", \"description\": \"Writes cover letters\", \"prompt\": COVER_LETTER_PROMPT}, ] return create_deep_agent(tools, INSTRUCTIONS, subagents=subagents, model=llm) def make_task_prompt(resume_text: str, skills_hint: str, title: str, location: str) -> str: skills = skills_hint.strip() skill_line = f\" Prioritize these skills: {skills}.\" if skills else \"\" return ( f\"Target title: {title}\\n\" f\"Target location(s): {location}\\n\" f\"{skill_line}\\n\\n\" f\"RESUME RAW TEXT:\\n{resume_text[:8000]}\" ). resume_text = extract_text(uploaded) if uploaded else \"\" run_clicked = st.button(\"Run\", type=\"primary\", disabled=not uploaded) if run_clicked: st.session_state.last_error = \"\" st.session_state.raw_final = \"\" try: if not os.environ.get(\"OPENAI_API_KEY\"): st.error(\"OPENAI_API_KEY not set.\") st.stop() if not TAVILY_KEY: st.error(\"TAVILY_API_KEY not set.\") st.stop() agent = build_agent() task = make_task_prompt(resume_text, skills_hint, target_title, target_location) state = { \"messages\": [{\"role\": \"user\", \"content\": task}], \"files\": {\"cover_letters.md\": \"\"}, } with st.spinner(\"Finding jobs and drafting cover letters...\"): result = agent.invoke(state) final_msgs = result.get(\"messages\", []) final_text = (final_msgs[-1].content if final_msgs else \"\") or \"\" st.session_state.raw_final = final_text files = result.get(\"files\", {}) or {} cover_md = (files.get(\"cover_letters.md\") or \"\").strip() st.session_state.cover_doc = md_to_docx(cover_md) if cover_md else None raw_jobs = extract_jobs_from_text(final_text) jobs_list = normalize_jobs(raw_jobs) st.session_state.jobs_df = pd.DataFrame(jobs_list) if jobs_list else None st.success(\"Done.", "score": 0.64773196, "raw_content": "# LangChain's Deep Agents: A Guide With Demo Project\n\nLearn what deep agents are, their core components, and how to build a job application assistant using LangChain's deepagents package.\n\nAug 5, 2025 Â Â· 12 min read\n\nThe most common agent architecture today involves an LLM calling tools in a loop, which is simple, effective, but ultimately limited. While this approach works for straightforward tasks, it falls short when faced with complex, multi-step challenges that require planning, context management, and sustained execution over longer time horizons.\n\nLangChainâ€™s Deep Agents architecture combines detailed system prompts, planning tools, sub-agents, and file systems to create AI agents capable of tackling complex research, coding, and analytical tasks. Applications like Claude Code, Deep Research, and Manus have proven this approach's effectiveness, and now the `deepagents` Python package makes this architecture accessible to everyone.\n\nIn this tutorial, I'll explain step by step how to:\n\n* Build Deep Agents that handle complex workflows and manage context effectively\n* Create a job application assistant that searches for positions and generates tailored cover letters\n* Implement specialized sub-agents for focused task execution and context management\n\n## Multi-Agent Systems with LangGraph\n\nBuild powerful multi-agent systems by applying emerging agentic design patterns in the LangGraph framework.\n\n[Explore Course](https://www.datacamp.com/courses/multi-agent-systems-with-langgraph)\n\n## What Are Deep Agents?\n\n[Deep Agents](https://blog.langchain.com/deep-agents/) are an advanced agent architecture designed for handling complex, multi-step tasks that require sustained reasoning, tool use, and memory. Unlike traditional agents that operate in short loops or perform simple tool calls, Deep Agents plan their actions, manage evolving context, delegate subtasks to specialized sub-agents, and maintain state across long interactions. This architecture is already powering real-world applications like [Claude Code](https://www.datacamp.com/tutorial/claude-code), [Deep Research](https://www.datacamp.com/blog/deep-research-openai), and [Manus](https://www.datacamp.com/tutorial/manus-ai).\n\nSource: [LangChain](https://blog.langchain.com/deep-agents/)\n\nThese are the key Characteristics of Deep Agents:\n\n* Planning capability: They can break down large tasks into manageable subtasks and adjust the plan as work progresses.\n* Context management: They retain and reference important information across long conversations and multiple steps.\n* Sub-agent delegation: Deep Agents can launch specialized sub-agents to handle focused parts of a task.\n* File system integration: They persist and retrieve information as needed, enabling true â€œmemoryâ€ beyond a single conversation turn.\n* Detailed system prompts: Deep Agents follow explicit workflows for consistency and reliability while operating with sophisticated instructions and examples.\n\n## Core Components of Deep Agents\n\nDeep Agents overcome the limitations of traditional agents through four core components:\n\n### 1. Detailed system prompts\n\nUnlike simple instruction prompts, Deep Agents use comprehensive system prompts as follows:\n\n```\nDEEP_AGENT_SYSTEM_PROMPT = \"\"\" You are an expert research assistant capable of conducting thorough, multi-step investigations. Your capabilities include: PLANNING: Break complex tasks into subtasks using the todo_write tool RESEARCH: Use internet_search extensively to gather comprehensive information DELEGATION: Spawn sub-agents for specialized tasks using the call_subagent tool DOCUMENTATION: Maintain detailed notes using the file system tools When approaching a complex task: 1. First, create a plan using todo_write 2. Research systematically, saving important findings to files 3. Delegate specialized work to appropriate sub-agents 4. Synthesize findings into a comprehensive response Examples: [Detailed few-shot examples follow...] \"\"\"\n```\n\nThe prompt integrates planning, research, and delegation with documentation, utilizing few-shot examples to decompose complex tasks.\n\n### 2. Planning tools\n\nThe planning tool is often just a \"no-op\" that helps the agent organize its thoughts:\n\n```\n@tool def todo_write(tasks: List[str]) -> str: formatted_tasks = \"\\n\".join([f\"- {task}\" for task in tasks]) return f\"Todo list created:\\n{formatted_tasks}\"\n```\n\nThis simple tool provides important [context engineering](https://www.datacamp.com/blog/context-engineering), which forces the agent to plan accordingly and keep that plan visible throughout execution.\n\n### 3. Sub-agents\n\nDeep Agents can spawn specialized sub-agents for focused tasks. Each sub-agent is designed with its own prompt, description, and toolset, which enables both separation of concerns and deep task-specific optimization. Hereâ€™s an example of how you might define sub-agents in your workflow:\n\n```\nsubagents = [ { \"name\": \"research-agent\", \"description\": \"Conducts deep research on specific topics\", \"prompt\": \"You are a research specialist. Focus intensively on the given topic...\", \"tools\": [\"internet_search\", \"read_file\", \"write_file\"] }, { \"name\": \"analysis-agent\", \"description\": \"Analyzes data and draws insights\", \"prompt\": \"You are a data analyst. Examine the provided information...\", \"tools\": [\"read_file\", \"write_file\"] } ]\n```\n\nThis approach provides context quarantine, which means that each sub-agent maintains its own context and does not pollute the main agentâ€™s memory. By isolating specialized tasks, you can enable:\n\n* Prompt specialization: Each agent can be fine-tuned for its unique function with targeted instructions and examples.\n* Cleaner context management: The main agentâ€™s context remains focused and unburdened by irrelevant details, while sub-agents operate within their own boundaries.\n* Modular reasoning: Tasks can be delegated, parallelized, or iteratively refined, making it easy to scale your agent system to new domains.\n\n### 4. File system integration\n\nDeep Agents maintain and share state using a virtual file system. Instead of relying solely on conversation history, these built-in tools allow agents to organize information throughout a workflow:\n\n```\ntools = [ \"ls\", # List files \"read_file\", # Read file contents \"write_file\", # Write to file \"edit_file\" # Edit existing file ]\n```\n\nThis virtual file system offers several advantages:\n\n* Persistent memory: Agents can store key findings, notes, or intermediate results in files, making this information accessible across multiple steps and even to sub-agents.\n* Shared workspace: Multiple agents (or sub-agents) can collaborate by reading from and writing to the same files, enabling teamwork within a single workflow.\n* Information organization: Complex, multi-step tasks become easier to manage as agents can create, categorize, and reference documents or artifacts as needed.\n\n## Demo: Building a Job Application Assistant With LangChain's `deepagents`\n\nI will walk you through a practical example of building a job application assistant that automatically finds relevant job openings and generates tailored cover letters for the user.\n\nOur assistant will:\n\n* Search for current job postings based on user-specified criteria\n* Filter and rank jobs according to skill matching\n* Generate personalized cover letters for each role\n* Package all results in a downloadable format for the user\n\n### Step 1: Initial setup and dependencies\n\nLet's start with a basic installation and setup:\n\n```\npip install deepagents pip install tavily-python pip install streamlit pip install langchain-openai\n```\n\nOnce installed, we set up our environment variables:\n\n```\nexport OPENAI_API_KEY=sk-projxxxxxxxxxxxxxxxxxxx export TAVILY_API_KEY=tvly-devxxxxxxxxxxxxxxxxxxx\n```\n\nFor this demo, youâ€™ll need both an OpenAI API key (for GPT-4o mini model) and a Tavily API key (for web search functionality). Tavily provides the agent with up-to-date job postings directly from the web, while OpenAIâ€™s model handles all the language understanding, reasoning, planning, and content generation.\n\nNote: New Tavily users receive 1,000 free API credits. To get your key, just sign up at<https://app.tavily.com>.\n\nFinally, weâ€™ll import the necessary libraries and set up the [Streamlit](https://www.datacamp.com/tutorial/how-to-build-user-interfaces-for-ai-applications-using-streamlit-and-langchain) interface:\n\n```\nimport os import io import json import re from typing import Literal, Dict, Any, List import streamlit as st import pandas as pd from langchain_core.tools import tool from langchain_openai import ChatOpenAI from tavily import TavilyClient from deepagents import create_deep_agent\n```\n\nThis step imports all the required dependencies for our deep agent application. We use `streamlit` for the web interface, `pandas` for data handling, `langchain_openai` for the LLM integration, and `deepagents` for our agent framework.\n\n### Step 2: Session state management\n\nNext, we initialize Streamlitâ€™s session state to persist data between user interactions. This ensures the app remembers uploaded files, results, and error states, even as users interact with the interface:\n\n```\nif \"jobs_df\" not in st.session_state: st.session_state.jobs_df = None if \"cover_doc\" not in st.session_state: st.session_state.cover_doc = None if \"last_error\" not in st.session_state: st.session_state.last_error = \"\" if \"raw_final\" not in st.session_state: st.session_state.raw_final = \"\"\n```\n\nThis setup is essential for a smooth user experience, allowing us to store the job results, generated cover letters, and any error messages throughout the session.\n\n### Step 3: User interface setup\n\nWe use Streamlit columns to organize input fields within our UI for the resume upload, job title, location, and optional skills:\n\n```\nst.set_page_config(page_title=\"Job Application Assistant\", page_icon=\" \", layout=\"wide\") st.title(\"ðŸ’¼ Job Application Assistant\") c0, c1, c2 = st.columns([2, 1, 1]) with c0: uploaded = st.file_uploader(\"Upload your resume (PDF/DOCX/TXT)\", type=[\"pdf\", \"docx\", \"txt\"]) with c1: target_title = st.text_input(\"Target title\", \"Senior Machine Learning Engineer\") with c2: target_location = st.text_input(\"Target location(s)\", \"Bangalore OR Remote\") skills_hint = st.text_area( \"Add/override skills (optional)\", \"\", placeholder=\"Python, PyTorch, LLMs, RAG, Azure, vLLM, FastAPI\", )\n```\n\nThe UI is organized into columns for better layout. Users can upload their resume in multiple formats, specify their target job title and location, and highlight specific skills they want to emphasize in their applications.\n\n### Step 4: File processing helper functions\n\nNext, we implement robust file processing to handle different resume formats and extract texts from them.\n\n```\n import pypdf import docx def extract_text(file) -> str: if not file: return \"\" name = file.name.lower() if name.endswith(\".txt\"): return file.read().decode(\"utf-8\", errors=\"ignore\") if name.endswith(\".pdf\"): pdf = pypdf.PdfReader(io.BytesIO(file.read())) return \"\\n\".join((p.extract_text() or \"\") for p in pdf.pages) if name.endswith(\".docx\"): d = docx.Document(io.BytesIO(file.read())) return \"\\n\".join(p.text for p in d.paragraphs) return \"\" def md_to_docx(md_text: str) -> bytes: doc = docx.Document() for raw in md_text.splitlines(): line = raw.rstrip() if not line: doc.add_paragraph(\"\") continue if line.startswith(\"#\"): level = min(len(line) - len(line.lstrip(\"#\")), 3) doc.add_heading(line.lstrip(\"#\").strip(), level=level) elif line.startswith((\"- \", \"* \")): doc.add_paragraph(line[2:].strip(), style=\"List Bullet\") else: doc.add_paragraph(line) bio = io.BytesIO() doc.save(bio) bio.seek(0) return bio.read()\n```\n\nThese helper functions handle the complexity of extracting text from different file formats (PDF, DOCX, TXT) and converting markdown output back to DOCX format for download. Here is how each function works:\n\n* The `extract_text()` function automatically detects the uploaded file type (TXT, PDF, or DOCX) and extracts the content using the appropriate library, so users donâ€™t need to worry about the file format.\n* The `md_to_docx()` function takes markdown-formatted text (such as cover letters generated by the agent) and converts it into a clean, well-structured Word document ready for download.\n\nThis ensures the application can flexibly handle diverse resume input and deliver professional outputs regardless of the original file format.\n\n### Step 5: Data processing and extraction\n\nNext, we implement robust parsing to extract job data from the agent's response.\n\n```\ndef normalize_jobs(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]: normed = [] for it in items: if not isinstance(it, dict): continue # case-insensitive keys lower_map = {str(k).strip().lower(): it[k] for k in it.keys()} company = str(lower_map.get(\"company\", \"\") or \"\").strip() title = str(lower_map.get(\"title\", \"\") or \"\").strip() location = str(lower_map.get(\"location\", \"\") or \"\").strip() link = str(lower_map.get(\"link\", \"\") or \"\").strip() why_fit = str(lower_map.get(\"why_fit\", lower_map.get(\"good match\", \"\")) or \"\").strip() if not link: continue normed.append({ \"company\": company or \"â€”\", \"title\": title or \"â€”\", \"location\": location or \"â€”\", \"link\": link, \"Good Match\": \"Yes\" if why_fit else \"â€”\", }) return normed[:5] def extract_jobs_from_text(text: str) -> List[Dict[str, Any]]: if not text: return [] pattern = r\"\\s*(?:```[\\w-]*\\s*)?(\\[.*?\\])\\s*(?:```)?\\s*\" m = re.search(pattern, text, flags=re.S | re.I) if not m: return [] raw = m.group(1).strip().strip(\"`\").strip() try: obj = json.loads(raw) return obj if isinstance(obj, list) else [] except Exception: try: salvaged = re.sub(r\"(?\n```\n\nLetâ€™s understand the above functions briefly:\n\n* The `extract_jobs_from_text()` function uses a regular expression to extract a JSON array of jobs from the agentâ€™s structured output (inside ... tags). Fallback parsing is also included to handle minor model mistakes, such as returning single quotes instead of double quotes in JSON.\n* Then the `normalize_jobs()` function standardizes and cleans up each job dictionary, like case-insensitive keys, required fields, and whitespace stripping, and limits the output to the top 5 entries.\n\n### Step 6: Tool integration\n\nThe heart of the research capability is powered by Tavily. Thus, we define a web search tool that the deep agent will use to find up-to-date job listings:\n\n```\nTAVILY_KEY = os.environ.get(\"TAVILY_API_KEY\", \"\") @tool def internet_search( query: str, max_results: int = 5, topic: Literal[\"general\", \"news\", \"finance\"] = \"general\", include_raw_content: bool = False, ) -> List[Dict[str, Any]]: if not TAVILY_KEY: raise RuntimeError(\"TAVILY_API_KEY is not set in the environment.\") client = TavilyClient(api_key=TAVILY_KEY) return client.search( query=query, max_results=max_results, include_raw_content=include_raw_content, topic=topic, )\n```\n\nThe `internet_search()` function is decorated with `@tool`, making it accessible to the agent and sub-agents. It then calls the Tavily API, which returns relevant, recent search results, making it ideal for dynamic job queries and research.\n\nNote: You can add more tools this way (such as document summarization, code execution, or data enrichment) to further extend your deep agentâ€™s abilities.\n\n### Step 7: Deep agent configuration\n\nNow, we bring everything together by configuring the main agent and its sub-agents, each with targeted instructions as follows:\n\n```\nINSTRUCTIONS = ( \"You are a job application assistant. Do two things:\\n\" \"1) Use the web search tool to find exactly 5 CURRENT job postings (matching the user's target title, locations, and skills). \" \"Return them ONLY as JSON in this exact wrapper:\\n\" \"\\n\" \"[{\\\"company\\\":\\\"...\\\",\\\"title\\\":\\\"...\\\",\\\"location\\\":\\\"...\\\",\\\"link\\\":\\\"https://...\\\",\\\"Good Match\\\":\\\"one sentence\\\"}, ... five total]\\n\" \"\\n\" \"Rules: The list must be valid JSON (no comments), real links to the job page or application page, no duplicates.\\n\" \"2) Produce a concise cover letter (â‰¤150 words) for EACH job, with a subject line, appended to cover_letters.md under a heading per job.\\n\" \"Do not invent jobs. Prefer reputable sources (company career pages, LinkedIn, Lever, Greenhouse).\" ) JOB_SEARCH_PROMPT = ( \"Search and select 5 real postings that match the user's title, locations, and skills. \" \"Output ONLY this block format (no extra text before/after the wrapper):\\n\" \"\\n\" \"[{\\\"company\\\":\\\"...\\\",\\\"title\\\":\\\"...\\\",\\\"location\\\":\\\"...\\\",\\\"link\\\":\\\"https://...\\\",\\\"Good Match\\\":\\\"one sentence\\\"},\" \" {\\\"company\\\":\\\"...\\\",\\\"title\\\":\\\"...\\\",\\\"location\\\":\\\"...\\\",\\\"link\\\":\\\"https://...\\\",\\\"Good Match\\\":\\\"one sentence\\\"},\" \" {\\\"company\\\":\\\"...\\\",\\\"title\\\":\\\"...\\\",\\\"location\\\":\\\"...\\\",\\\"link\\\":\\\"https://...\\\",\\\"Good Match\\\":\\\"one sentence\\\"},\" \" {\\\"company\\\":\\\"...\\\",\\\"title\\\":\\\"...\\\",\\\"location\\\":\\\"...\\\",\\\"link\\\":\\\"https://...\\\",\\\"Good Match\\\":\\\"one sentence\\\"},\" \" {\\\"company\\\":\\\"...\\\",\\\"title\\\":\\\"...\\\",\\\"location\\\":\\\"...\\\",\\\"link\\\":\\\"https://...\\\",\\\"Good Match\\\":\\\"one sentence\\\"}]\" \"\\n\" ) COVER_LETTER_PROMPT = ( \"For each job in the found list, write a subject line and a concise cover letter (â‰¤150 words) that ties the user's skills/resume to the role. \" \"Append to cover_letters.md under a heading per job. Keep writing tight and specific.\" ) def build_agent(): api_key = os.environ.get(\"OPENAI_API_KEY\") if not api_key: st.error(\"Please set OPENAI_API_KEY in your environment.\") st.stop() llm = ChatOpenAI(model=os.environ.get(\"OPENAI_MODEL\", \"gpt-4o-mini\"), temperature=0.2) tools = [internet_search] subagents = [ {\"name\": \"job-search-agent\", \"description\": \"Finds relevant jobs\", \"prompt\": JOB_SEARCH_PROMPT}, {\"name\": \"cover-letter-writer-agent\", \"description\": \"Writes cover letters\", \"prompt\": COVER_LETTER_PROMPT}, ] return create_deep_agent(tools, INSTRUCTIONS, subagents=subagents, model=llm) def make_task_prompt(resume_text: str, skills_hint: str, title: str, location: str) -> str: skills = skills_hint.strip() skill_line = f\" Prioritize these skills: {skills}.\" if skills else \"\" return ( f\"Target title: {title}\\n\" f\"Target location(s): {location}\\n\" f\"{skill_line}\\n\\n\" f\"RESUME RAW TEXT:\\n{resume_text[:8000]}\" )\n```\n\nThis step demonstrates the power of Deep Agents through specialized sub-agents. The main instructions provide overall guidance, while each sub-agent has focused prompts for specific tasks:\n\n* `INSTRUCTIONS`, `JOB_SEARCH_PROMPT`, and `COVER_LETTER_PROMPT` define the main system prompt and specialized instructions for each sub-agent. This ensures the agent always produces well-structured job results and tailored cover letters in the required format.\n* The `build_agent()` function checks for the OpenAI API key, sets up the language model, and creates the deep agent with both the job search and cover letter sub-agents. This modular setup lets each sub-agent focus on its part of the workflow.\n* Then `make_task_prompt()` function generates a single prompt that combines the userâ€™s resume, skills, job title, and location. This gives the agent all the context it needs to start the search and drafting process.\n\nTogether, these functions add structure and specialization in the workflow.\n\n### Step 8: Main application logic\n\nThis step is the core application logic that handles user input and orchestrates the deep agent:\n\n```\nresume_text = extract_text(uploaded) if uploaded else \"\" run_clicked = st.button(\"Run\", type=\"primary\", disabled=not uploaded) if run_clicked: st.session_state.last_error = \"\" st.session_state.raw_final = \"\" try: if not os.environ.get(\"OPENAI_API_KEY\"): st.error(\"OPENAI_API_KEY not set.\") st.stop() if not TAVILY_KEY: st.error(\"TAVILY_API_KEY not set.\") st.stop() agent = build_agent() task = make_task_prompt(resume_text, skills_hint, target_title, target_location) state = { \"messages\": [{\"role\": \"user\", \"content\": task}], \"files\": {\"cover_letters.md\": \"\"}, } with st.spinner(\"Finding jobs and drafting cover letters...\"): result = agent.invoke(state) final_msgs = result.get(\"messages\", []) final_text = (final_msgs[-1].content if final_msgs else \"\") or \"\" st.session_state.raw_final = final_text files = result.get(\"files\", {}) or {} cover_md = (files.get(\"cover_letters.md\") or \"\").strip() st.session_state.cover_doc = md_to_docx(cover_md) if cover_md else None raw_jobs = extract_jobs_from_text(final_text) jobs_list = normalize_jobs(raw_jobs) st.session_state.jobs_df = pd.DataFrame(jobs_list) if jobs_list else None st.success(\"Done. Results generated and saved.\") except Exception as e: st.session_state.last_error = str(e) st.error(f\"Error: {e}\")\n```\n\nThe above code handles user actions, launches the deep agent, and displays results as follows:\n\n* When the user clicks Run, the app checks that required API keys are present.\n* It extracts the resume, gathers inputs (skills, title, location), and constructs the task prompt.\n* The agent is invoked, passing in both the userâ€™s query and a file placeholder for cover letters.\n* As the agent completes its workflow, the app:\n\n+ Extracts and saves the generated cover letters (converted to DOCX for download)\n+ Parses, normalizes, and displays the job matches as an interactive DataFrame\n\n### Step 9: Results display and download\n\nFinally, we present the results in a user-friendly format:\n\n```\nst.header(\"Jobs\") if st.session_state.jobs_df is None or st.session_state.jobs_df.empty: st.write(\"No jobs to show yet.\") else: df = st.session_state.jobs_df.copy() def as_link(u: str) -> str: u = u if isinstance(u, str) else \"\" return f'Apply' if u else \"â€”\" if \"link\" in df.columns: df[\"link\"] = df[\"link\"].apply(as_link) cols = [c for c in [\"company\", \"title\", \"location\", \"link\", \"Good Match\"] if c in df.columns] df = df[cols] st.write(df.to_html(escape=False, index=False), unsafe_allow_html=True) st.header(\"Download\") if st.session_state.cover_doc: st.download_button( \"Download cover_letters.docx\", data=st.session_state.cover_doc, file_name=\"cover_letters.docx\", mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\", key=\"dl_cover_letters\", ) else: st.caption(\"Cover letters not produced yet.\")\n```\n\nAfter the agent finishes, we present the results in a polished layout i.e.:\n\n* The app displays job matches in a table, with clickable Apply links for each position.\n* If cover letters are available, a download button lets users save them as a Word document.\n\nThis turns a multi-step AI workflow into a simple one-click experience.\n\nTo launch the app, simply run:\n\n```\nstreamlit app.py\n```\n\n## Conclusion\n\nDeep Agents represent a significant evolution in agent architecture, moving beyond simple tool-calling to sophisticated systems capable of planning, delegation, and sustained execution on complex tasks. The `deepagents` package makes this architecture accessible, allowing developers to build production-ready agents for research, coding, analysis, and specialized domains.\n\nAs AI agents become essential in business and research, deep agent architectures provide the structure and flexibility needed for real-world impact. I also recommend checking out the [LangSmith Agent Builder tutorial](https://www.datacamp.com/tutorial/langsmith-agent-builder-tutorial) if you're looking for a no-code solution.\n\n---\n\nAuthor\n\n[Aashi Dutt](/portfolio/aashidutt3)\n\nI am a Google Developers Expert in ML(Gen AI), a Kaggle 3x Expert, and a Women Techmakers Ambassador with 3+ years of experience in tech. I co-founded a health-tech startup in 2020 and am pursuing a master's in computer science at Georgia Tech, specializing in machine learning.\n\nTopics\n\n[AI Agents](/tutorial/category/ai-agents)[Artificial Intelligence](/tutorial/category/ai)\n\nLearn AI with these courses!\n\nCourse\n\n### [Deploying AI into Production with FastAPI](/courses/deploying-ai-into-production-with-fastapi)\n\n4 hr\n\n2.9K\n\nLearn how to use FastAPI to develop APIs that support AI models, built to meet real-world demands.\n\n[See Details](/courses/deploying-ai-into-production-with-fastapi)[Start Course](/users/sign_up?redirect=%2Fcourses%2Fdeploying-ai-into-production-with-fastapi%2Fcontinue)\n\nCourse\n\n### [Building AI Agents with Google ADK](/courses/building-ai-agents-with-google-adk)\n\n1 hr\n\n3.7K\n\nBuild a customer-support assistant step-by-step with Googleâ€™s Agent Development Kit (ADK).\n\n[See Details](/courses/building-ai-agents-with-google-adk)[Start Course](/users/sign_up?redirect=%2Fcourses%2Fbuilding-ai-agents-with-google-adk%2Fcontinue)\n\nCourse\n\n### [Introduction to AI Agents](/courses/introduction-to-ai-agents)\n\n1 hr 30 min\n\n38.3K\n\nLearn the fundamentals of AI agents, their components, and real-world useâ€”no coding required.\n\n[See Details](/courses/introduction-to-ai-agents)[Start Course](/users/sign_up?redirect=%2Fcourses%2Fintroduction-to-ai-agents%2Fcontinue)\n\n[See More](https://www.datacamp.com/category/artificial-intelligence)\n\nRelated\n\n[Tutorial\n\n### Jan-V1: A Guide With Demo Project](/tutorial/jan-v1)\n\nLearn how to build a Deep Research Assistant using Jan-v1's agentic reasoning capabilities, including local deployment, Streamlit app development, and more.\n\nAashi Dutt\n\n[Tutorial\n\n### Building LangChain Agents to Automate Tasks in Python](/tutorial/building-langchain-agents-to-automate-tasks-in-python)\n\nA comprehensive tutorial on building multi-tool LangChain agents to automate tasks in Python using LLMs and chat models using OpenAI.\n\nBex Tuychiev\n\n[Tutorial\n\n### Introduction to LangChain for Data Engineering & Data Applications](/tutorial/introduction-to-langchain-for-data-engineering-and-data-applications)\n\nLangChain is a framework for including AI from large language models inside data pipelines and applications. This tutorial provides an overview of what you can do with LangChain, including the problems that LangChain solves and examples of data use cases.\n\nRichie Cotton\n\n[Tutorial\n\n### Mistral Agents API: A Guide With Demo Project](/tutorial/mistral-agents-api)\n\nLearn how to build AI agents using Mistral's Agents API, and explore key concepts like tool usage, connectors, handoffs, and more.\n\nAashi Dutt\n\n[Tutorial\n\n### Chainlit: A Guide With Practical Examples](/tutorial/chainlit)\n\nLearn what Chainlit is, how to install it, and how to run it to build interactive interfaces for LLM-powered applications.\n\nAashi Dutt\n\n[code-along\n\n### Building AI Applications with LangChain and GPT](/code-along/building-ai-applications-with-langchain-and-gpt)\n\nIn the live training, you'll use LangChain to build a simple AI application, including preparing and indexing data, prompting the AI, and generating responses.\n\nEmmanuel Pire\n\n[See More](/tutorial/category/ai-agents)[See More](/tutorial/category/ai-agents)"}, {"url": "https://dev.to/bsorrentino/langgraph4j-deep-agents-agent-20-1d74", "title": "LangGraph4j Deep Agents (Agent 2.0) - DEV Community", "content": "**Deep Agents** try fix this by **changing the architecture** (not just the prompt) based on the four pillars below:. 2. **Hierarchical Delegation (Sub-Agents)** â€“ An **Orchestrator** delegates to specialized agents (Researcher, Coder, Writer, â€¦), each working in a clean context and returning synthesized results. This repository demonstrates the four pillars of Deep Agents, it includes sample code that create a **Deep Researcher Agent** that use Tavily as web search engine and **OpenAI gpt-4o-mini model**. // Create a Research Sub Agent var researchSubagent = DeepAgent. Instead, you should break down a large topic into the necessary components, and then call multiple research agents in parallel, one for each sub question. build();// Create a Critique Sub Agent var critiqueSubAgent = DeepAgent. Use the research-agent to conduct deep research. Deep Agents architecture is a try **to move beyond one-loop â€œshallowâ€ agents** to explicit planning hierarchical delegation, persistent memory, and rigorous context engineering.", "score": 0.6164054, "raw_content": " [Skip to content](#main-content)\n\n[Log in](https://dev.to/enter?signup_subforem=1)    [Create account](https://dev.to/enter?signup_subforem=1&state=new-user)\n\n## DEV Community\n\n[bsorrentino](/bsorrentino)\n\nPosted on\n\n# ðŸ§ ðŸ¤– LangGraph4j Deep Agents (Agent 2.0)\n\n[#langgraph4j](/t/langgraph4j) [#ai](/t/ai) [#agents](/t/agents) [#springai](/t/springai)\n\n## Why Deep Agents (Agent 2.0)?\n\nClassic agents often run a simple loop: **think â†’ call a tool â†’ observe â†’ repeat**. Thatâ€™s great for quick, transactional queries, but it breaks down on multi-hour or multi-day tasks (hallucinations, loss of goal, looping, no recovery).  \n  \n **Deep Agents** try fix this by **changing the architecture** (not just the prompt) based on the four pillars below:\n\n1. **Explicit Planning** â€“ The agent continuously maintains a plan (e.g., a TODO in Markdown) with clear statuses instead of hiding intent in a just chain-of-thought.\n2. **Hierarchical Delegation (Sub-Agents)** â€“ An **Orchestrator** delegates to specialized agents (Researcher, Coder, Writer, â€¦), each working in a clean context and returning synthesized results.\n3. **Persistent Memory** â€“ Intermediate artifacts (notes, code, data) are written to external storage (filesystem, vector store, â€¦) and referenced by path/query rather than stuffing everything into the context window.\n4. **Extreme Context Engineering** â€“ Long, specific instructions define: when to plan vs. act, when to spawn sub-agents and the human-in-the-loop(HITL) rules.\n\n## Reference Architecture\n\n## Reference Implementation in Java using LangGraph4j\n\nSince the [LangGraph4j](https://github.com/langgraph4j/langgraph4j) is inpired by (more popular) [LangGraph](https://github.com/langchain-ai/langgraph) python version, I've decided to adapt its python based [Deep Agents reference implementation](https://github.com/langchain-ai/deepagents) to Java using [LangGraph4j](https://github.com/langgraph4j/langgraph4j) and [Spring AI](https://spring.io/projects/spring-ai).\n\nThe project is on [Github](https://github.com/langgraph4j/langgraph4j-deepagents.git). This repository demonstrates the four pillars of Deep Agents, it includes sample code that create a **Deep Researcher Agent** that use [Tavily](https://www.tavily.com) as web search engine and **OpenAI gpt-4o-mini model**.\n\nLet's look at a sequence diagram for a Deep Agent handling a complex request:\n\nBelow a representative code snippet that implements the Deep Agents in the diagram\n\n```\n// Create a Research Sub Agent var researchSubagent = DeepAgent. SubAgent. builder(). name(\"research-agent\"). description(\"\"\" Used to research more in depth questions. Only give this researcher one topic at a time. Do not pass multiple sub questions to this researcher. Instead, you should break down a large topic into the necessary components, and then call multiple research agents in parallel, one for each sub question. \"\"\"). prompt(\"\"\" You are a dedicated researcher. Your job is to conduct research based on the users questions. Conduct thorough research and then reply to the user with a detailed answer to their question ........(to be continued).............. \"\"\"). tools(List. of(\"internet_search\")). build();// Create a Critique Sub Agent var critiqueSubAgent = DeepAgent. SubAgent. builder(). name(\"critique-agent\"). description(\"Used to critique the final report. Give this agent some information about how you want it to critique the report.\"). prompt(\"\"\" You are a dedicated editor. You are being tasked to critique a report. You can find the report at `final_report.md`. You can find the question/topic for this report at `question.txt`. ........(to be continued).............. \"\"\"). build();// Create a Main Agent var deepAgent = DeepAgent. builder(). instructions(\"\"\" You are an expert researcher. Your job is to conduct thorough research, and then write a polished report. The first thing you should do is to write the original user question to `question.txt` so you have a record of it. Use the research-agent to conduct deep research. It will respond to your questions/topics with a detailed answer. When you think you enough information to write a final report, write it to `final_report.md` You can call the critique-agent to get a critique of the final report. After that (if needed) you can do more research and edit the `final_report.md` ........(to be continued).............. \"\"\"). subAgents(List. of(researchSubagent, critiqueSubAgent)). chatModel(chatModel). tools(List. of(tools. internetSearch())). build(). compile(CompileConfig. builder(). recursionLimit(100). build()); var userMessage = \"\"\" What is langgraph4j project? \"\"\"; var runnableConfig = RunnableConfig. builder(). build(); var result = agent. stream(Map. of(\"messages\", new UserMessage(userMessage), runnableConfig); var output = result. stream(). peek(s -> System. out. println(s. node())). reduce((a, b) -> b). orElseThrow(); System. out. println(\"\"\" ================================ TODO ================================ \"\"\"); output. state(). todos(). forEach((value) -> System. out. printf(\"\"\" ----------- %s ----------- \"\"\", value)); System. out. println(\"\"\" ================================ FILES ================================ \"\"\"); output. state(). files(). forEach((key, value) -> System. out. printf(\"\"\" file: '%s' ----------- %s ----------- \"\"\", key, value)); System. out. println(\"\"\" ================================ FINAL RESULT ================================ \"\"\"); System. out. printf(\"result: %s\\n\", output. state(). lastMessage(). map(AssistantMessage. class:: cast). map(AssistantMessage:: getText). orElseThrow());\n```\n\n## Conclusions\n\nDeep Agents architecture is a try **to move beyond one-loop â€œshallowâ€ agents** to explicit planning hierarchical delegation, persistent memory, and rigorous context engineering. [LangGraph4j](https://github.com/langgraph4j/langgraph4j) can help to experiment in Labs and deliver in production complex Agentic Workflow on top of JVM.   \n Checkout project, try it and let me know your feedback and ... happy AI coding! ðŸ‘‹\n\n## References\n\n* [Deep Agents (LangChain Blog)](https://blog.langchain.com/deep-agents/)\n* [Langchain Deepagents (Github)](https://github.com/hwchase17/deepagents)\n* [Agents 2.0: From Shallow to Deep Agents (Phil Schmid Blog)](https://www.philschmid.de/agents-2.0-deep-agents)\n\n---\n\nOriginally published at [https://bsorrentino.github.io](https://bsorrentino.github.io/bsorrentino/ai/2025/10/17/langgraph4j-deepagents.html) on October 17, 2025.\n\n## Top comments (0)\n\nSubscribe\n\nFor further actions, you may consider blocking this person and/or [reporting abuse](/report-abuse)\n\nWe're a place where coders share, stay up-to-date and grow their careers.\n\n[Log in](https://dev.to/enter?signup_subforem=1)   [Create account](https://dev.to/enter?signup_subforem=1&state=new-user)\n\n "}], "response_time": 0.71, "request_id": "8dda0853-1dc8-4f41-87c7-009fab0bbb30"}